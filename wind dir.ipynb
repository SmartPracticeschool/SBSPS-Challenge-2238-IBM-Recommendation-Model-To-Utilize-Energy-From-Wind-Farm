{"cells": [{"metadata": {}, "cell_type": "code", "source": "!pip install TensorFlow 2.0", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: TensorFlow in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.13.1)\nCollecting 2.0\n\u001b[31m  ERROR: Could not find a version that satisfies the requirement 2.0 (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for 2.0\u001b[0m\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM \nfrom math import sqrt\nfrom matplotlib import pyplot\nimport numpy as np\nimport pandas as pd", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Hardcode all variables\nwindow_size = 48\nbatch_size_exp = 1\nepoch_exp = 10\nneurons_exp = 50\npredict_values_exp = 8760\nlag_exp=48", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# frame a sequence as a supervised learning problem\ndef timeseries_to_supervised(data, lag=1):\n    df = DataFrame(data)\n    columns = [df.shift(i) for i in range(1, lag+1)]\n    columns.append(df)\n    df = concat(columns, axis=1)\n    df.fillna(0, inplace=True)\n    return df", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# invert differenced value\ndef inverse_difference(history, yhat, interval=1):\n    return yhat + history[-interval]", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# scale train and test data to [-1, 1]\n'''\ndef scale(train, test):\n    # fit scaler\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler = scaler.fit(train)\n    # transform train\n    train = train.reshape(train.shape[0], train.shape[1])\n    train_scaled = scaler.transform(train)\n    # transform test\n    test = test.reshape(test.shape[0], test.shape[1])\n    test_scaled = scaler.transform(test)\n    return scaler, train_scaled, test_scaled\n'''\ndef scale(data_norm):\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler = scaler.fit(data_norm)\n    # transform train\n    data_norm = data_norm.reshape(data_norm.shape[0], data_norm.shape[1])\n    data_scaled = scaler.transform(data_norm)\n    return scaler, data_scaled\n   ", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# inverse scaling for a forecasted value\ndef invert_scale(scaler, X, value):\n    new_row = [x for x in X] + [value]\n    array = np.array(new_row)\n    array = array.reshape(1, len(array))\n    inverted = scaler.inverse_transform(array)\n    return inverted[0, -1]", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# inverse scaling for a forecasted value\ndef invert_scale(scaler, X, value):\n    new_row = [x for x in X] + [value]\n    array = np.array(new_row)\n    array = array.reshape(1, len(array))\n    inverted = scaler.inverse_transform(array)\n    return inverted[0, -1]", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# make a one-step forecast\ndef forecast_lstm(model, batch_size, X):\n    X = X.reshape(1, 1, len(X))\n    #print(X)\n    yhat = model.predict(X, batch_size=1)\n    return yhat[0,0]", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_0f72c3de9a7a4f7393cd4e6920ff54a5 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='2BMyH7881xc88eM5x9RpXWRd5k1SkDmgHbtuXbYUUw86',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_0f72c3de9a7a4f7393cd4e6920ff54a5.get_object(Bucket='windenen-donotdelete-pr-pwredmcvuwo9jl',Key='winddirtime.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nseries= pd.read_csv(body,index_col=\"Date/Time\")\nseries.head()\n", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "                  Wind Direction (\u00b0)\nDate/Time                           \n01 01 2018 00:00          259.994904\n01 01 2018 00:10          268.641113\n01 01 2018 00:20          272.564789\n01 01 2018 00:30          271.258087\n01 01 2018 00:40          265.674286", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Wind Direction (\u00b0)</th>\n    </tr>\n    <tr>\n      <th>Date/Time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01 01 2018 00:00</th>\n      <td>259.994904</td>\n    </tr>\n    <tr>\n      <th>01 01 2018 00:10</th>\n      <td>268.641113</td>\n    </tr>\n    <tr>\n      <th>01 01 2018 00:20</th>\n      <td>272.564789</td>\n    </tr>\n    <tr>\n      <th>01 01 2018 00:30</th>\n      <td>271.258087</td>\n    </tr>\n    <tr>\n      <th>01 01 2018 00:40</th>\n      <td>265.674286</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "for i in range(0,10):\n  series = series[:-1]\nseries.tail()", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "                  Wind Direction (\u00b0)\nDate/Time                           \n31 12 2018 21:30           79.699562\n31 12 2018 21:40           80.132507\n31 12 2018 21:50           80.081612\n31 12 2018 22:00           80.452248\n31 12 2018 22:10           80.960693", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Wind Direction (\u00b0)</th>\n    </tr>\n    <tr>\n      <th>Date/Time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31 12 2018 21:30</th>\n      <td>79.699562</td>\n    </tr>\n    <tr>\n      <th>31 12 2018 21:40</th>\n      <td>80.132507</td>\n    </tr>\n    <tr>\n      <th>31 12 2018 21:50</th>\n      <td>80.081612</td>\n    </tr>\n    <tr>\n      <th>31 12 2018 22:00</th>\n      <td>80.452248</td>\n    </tr>\n    <tr>\n      <th>31 12 2018 22:10</th>\n      <td>80.960693</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# transform data to be stationary\nraw_values = series.values\ndiff_values = difference(raw_values, 1)", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# transform data to be supervised learning\nsupervised = timeseries_to_supervised(diff_values, lag_exp)\nsupervised_values = supervised.values", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# split data into train and test-sets\nscaler,supervised_values = scale(supervised_values)\ntrain_scaled, test_scaled = supervised_values[0:-predict_values_exp], supervised_values[-predict_values_exp:]\n#print(test_scaled)", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n  warnings.warn(msg, DataConversionWarning)\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "# fit the model\nlstm_model = fit_lstm(train_scaled, batch_size_exp, epoch_exp, neurons_exp)", "execution_count": 20, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'fit_lstm' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-20-0c3473bf298b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons_exp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'fit_lstm' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}